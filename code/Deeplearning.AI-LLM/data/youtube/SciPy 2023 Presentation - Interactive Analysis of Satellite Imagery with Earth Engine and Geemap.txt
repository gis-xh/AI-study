Okay, good morning, everyone. Thanks for coming and thank you for the organizers for putting this section together. And my name is Chusun Wu. I'm from the University of Tennessee. And my co-presenter is Steve Greenberg from at Google. And unfortunately, he could not be here today. But we have worked together to prepare this presentation and we try my best to represent our work as effectively as possible. And our title is Interactive Analysis of Satellite Imagery with Google's Engine and ZMap. You can scan the QR code at the lower right corner to access the slide if you want and also the link at the bottom there to get access to the slide. And here's the outline. First, I will introduce an interactive web app that allows you to create satellite time-lapse animation for anywhere around the globe using all kinds of satellite data. And then I will briefly introduce Google Earth Engine and ZMap. Then I will highlight some of the key features, what kind of things ZMap can do. And lastly, we'll show you some additional resources. On the right here, I showed you an animation. That one is actually a Landsat time-lapse animation. You can see how dynamic the river channel is changing. And not just for visualization, so you can do also all kinds of analysis to extract features from the satellite imagery, all without coding. So if you're interested, you can check out the link at the upper right corner there to access the web app. And so here's the interface. And you can, besides the Google Earth Engine, there are all kinds of other open source applications for you to visualize data. And here, I'm going to show you a quick tutorial. All you need is to zoom in to anywhere around the globe you like. Simply draw a rectangle, or you can upload an ROI from your computer. And then just select what satellite do you want. Landsat mode is all kind of satellite in the public domain. And then just adjust some parameters. Click the button. Within 20, 30 seconds, you should be able to get an animation for any area you like, and to show how the landscape is changing. It depends on the satellite data. So for Landsat, we have data since 1984. We have 30, 40 decades data. They can see the changes. And it's very effective. And this is a simple tool that you can utilize to showcase changes. Next, I'm going to quickly show you some examples that are quite interesting. For example, the drying of the ROC, mining in Canada, coastal expansion in Dubai, and also the river dynamics in Peru that I showed you at the beginning. And deforestation, landslide, quite interesting, lasting for decades of a landslide. It's difficult to see on the ground, but with longer time series, it's actually quite striking. And the famous urban growth in Las Vegas, and also see the region of how it's changing. Urban growth in China, in Mexico, coastal erosion in Spain, right? And so those are the three longer time span of the Landsat data, but there are tons of more satellite data available. So this is for Landsat, for example, 10 weeks, so within 24 hours, right? So we have data every hour, right? You can basically visualize all kinds of satellite data very easily, and you can create the animation. So next time, if you see some of this on social media, you can try to create one by your own, because now you know you have the tools, actually you can do that. But under the hood, it's a lot of computing, actually, to be able to generate something like this. And traditionally, it's actually very difficult. So you have ever using remote sensing data, trying to create this maybe 10 years ago, this can take you hours. You download the data, processing, remove cloud, and then mosaicing, all kinds of stuff, and then to download. So now it's simple, 20, 30 seconds, anywhere you like, and all kinds of satellite. So this is for temperature, but then you can do other, for example, sea surface temperature changing dynamics, or even vegetation dynamics, right? So you're studying how the vegetation is changing, this is quite effective. You can see how it's actually, the phenology changes throughout the seasons, right? Those are the human breezing, like this, but the Earth's actually very vibrant and very interesting. And those are relatively longer time span, like a high tempo, a low tempo frequency, but sometimes we need some very high tempo, like every five minutes, every 10 minutes. In this case, for example, the famous Tonga volcanic eruption, right? You see here, you can capture the data, you can capture the event, and then you can showcase how the impact of this kind of natural events. And on the right, so you need to get a wire fire, right? Wire fire is spreading, especially in California, and they are very, it become more and more frequent in recent years. And not just for visualization, you can also do analysis. You can actually check how the wire fire boundary is spreading. And these are very critical, especially for disaster and evacuation events. You need to know where it's going, and how it's going, and where it is right now. So all those things, information we can get through this kind of satellite data. So these are some of the simple examples. As I said, anything happening on the Earth's surface, usually at a certain scale, it can be captured by satellite data. And we have a longer time span, 30, 40 years. We also have data that have taken very quickly, every five minutes, 10 minutes. So most of the things that we can capture, we can analyze. And not just for visualization, the more important thing is to ask the question, why this is happening, and how it is happening, and where is it going, right? So those are more like scientific questions that people can think about and how to address that. And the app that I created is under the hood, empowered by Google's engine. So Google's engine is a cloud computing platform that can process data by data, and very efficiently, and it's free for research and education, and no profit. So you're welcome to sign up. And one of the questions you might ask is, why do we use Google's engine? Or why don't we just use the desktop to post the data that we have been doing for decades? So Google's engine is based on the cloud, so all we need is just a browser. And you can do like, data by scale, national scale, or global scale, within a couple of seconds. And you don't need to download the data. Just imagine, like, in the past, we watched a movie, we get to buy a DVD, we load into the CD-ROM, and you need a decent computer to be able to see that. Nowadays, you just YouTube, Netflix, right? You just watch a movie, search, then you watch. Nobody really downloads a movie anymore, like their local computer. Of course you can, but just like, you don't want to. You can just use a laptop, your cell phone, anything to watch. So the same idea here in the geospatial domain is that we're transforming from the desktop to the cloud. And so Google's engine has over 80 petabytes of data in the cloud. Most of the data in the public domain are already ingested. So you can use it in your fingertips. And you can use Python, you can use JavaScript. It also makes it much more accessible and reproducible. On the right here, so your diagram of all the journal publications you see using Google's engine. So you can see the exponential growth of users using this to do all kind of scientific studies. And one very simple application of Google's engine is like this. So we have satellite data, we have optical data, we have getting data, like for example, when they say every two weeks, right? And throughout the year, you get like a bunch of images for a couple decades, right? So cloud is a big problem in remote sensing for optical remote sensing. And essentially, what you can do is take a bunch of low quality images, and then generate something like, like this. So similar to on Google, as well, you see like, it's cloud free, it's perfect. But in reality, it's actually under who is in compute engine to process a lot of images, and then to generate something like this. So the image you see here is not taken from the same day, every pixel comes from a certain day, and then put all the pixels together. So the simplest one is take a median value, right? You have a lot of values, and the cloud usually high value. So you have a time series every pixel, you get the median usually is pretty good. And then you put all the pixels together, it becomes an image like this. So this is just like magic. And in first engine is client call, and you can do the global scale for any data you like. So it's very simple, easy to use. As I mentioned, it has over 80 petabyte data, so 80,000 terabyte, as long as you know how to access that one client call, and then you can not just access data, you can also do processing. So not just for visualization, there are a lot of things you can do, and all the data, landscape, Sentinel, MODIS, if you're familiar with remote sensing, readmaps, anything, most likely the data set you're using is already in the catalog. If not, you can upload your own data, and then you can utilize the parallel computing. So this is the so called the JavaScript co-editor. It's very easy to get started, and so we have a lot of functionalities for you to explore the data, and then write code, visualize the data, analyze, and then get some figures on the right here. And so it has a long history. So it started in 2010, and then around 2015, released for public application, and then a lot of build on top of this one. The JavaScript is very easy to get started, very powerful, and it has a good user interface. So you can think about Google Sending has two components, the compute, and also the visualization. So the JavaScript can do computation, it can also do visualization, but the Python API is just for computation. It has very limited visualization functionality, and the reason why we want to use Python is because we want to utilize the Python ecosystem. We have a lot of visualization libraries, we have desktop, we have ArcGIS, we have QGIS, and you also do a lot of machine learning stuff. So we want to actually utilize the Python, and you can also use the IDE of your choice, Visual Studio Code, Python, whatever you like. So Python to me is much more intuitive to me, and so that's why I built the package called gmap, kind of building on top of the Google Sending computation API, and then I have all the mapping libraries actually to be able to visualize it, and also utilize IPyWizard to create all kinds of intact widgets that allow users to interact with the Google Sending without having to write any line of code. So next, let me quickly introduce gmap. It's an open source package. You can check out the source code on GitHub. So I started this one roughly three years ago, and it has a lot of users right now using this to do mapping and visualization using Google Sending, and you support JupyterLab, Google Collect, or any basically Jupyter-based environment, and you can check out the website gmap.org. There are tons of documentation, API, examples, tutorials, videos, like that. I also published a short paper describing what this is about, and I was lucky to get support from NASA to help maintain and develop the package. So next, I will show you some tutorials. You can check out my YouTube channel. So I published over 500 videos over more than three days. So if you like, you can check out a lot of tutorials on my YouTube channel, and also for gmap specifically, I created 137 notebooks. So each notebook basically introduces one feature, one key feature of gmap. I will show you some demos later, but what I'm showing here is probably just 5% of the features that you can use with gmap. So each tutorial has a full-length video, maybe 15-20 minutes, and a GIF animation, like highlight 10-20 seconds, and also a notebook that you can reproduce. So all you need is just an account, and then just run through Colab or JupyterLab, whatever you like, and then you can see, you can reproduce what I did in those videos. But it takes, like, each video maybe 10-20 minutes, but sometimes it takes 10-20 hours actually to implement the feature, and then to be able to actually showcase that in the notebook. And also, I'm writing a book, so you can check out the link there. All the sources are open source, open access. You can check out more, like, systematic introduction into the package, how you can access the data, visualize the data, analyze the data, export the data, or create a map that you can use in your report or in your publications. So next, I'm going to show you more visual implementation, like what kind of things you can actually do, right? It's using a little bit cloud computing, but I want to know, like, what I want to watch a movie. How to actually watch the movie, right? So in this case, I want to access the data. How to actually access it? How to visualize it using the package? So the first one is the automatic conversion from JavaScript to Python. If you're already a JavaScript user, a Google Engine user, you might want to try this one, because just copy-paste, and I can convert the JavaScript API to Python. And in this one, you can get a result. So you can see here, like, you want to get access to the imagery, just a couple of clicks, then you can see what the imagery looks like. You can also sort the data. So this is similar, like, you sort the movie on the internet. You can sort any data you like in the data catalog, for example, lane cover, animation, anything you like. Select, import, run, you see the data. So you have the point for the data. It's not just for visualization. You can analyze, you can do all kinds of things you want. So lane cover, in the past, you had to go online to download gigabyte, gigabyte data, and then to load into a computer, and then trying to do analysis. Now you don't need to. All the data in there, you just need to know how to access that, right? And think about in a couple of years, for example, Laneset Next is going to be launched in 2030. And right now for Laneset 9, it's one gigabyte. So the next Laneset generation would be more than double the Spectral Bank and the resolution from 30 to 10. So basically the size is going to increase from one gigabyte to 20 gigabyte in the next seven years. So basically you have seven years to prepare yourself for the next generation. You don't want to download 20 gigabyte or one small piece of imagery to a computer to process. You probably want to try out the cloud. So this is what you can actually utilize. And you can also use the inspector. So DMAIC is basically all about, in the right here, all the widgets, right? You just need to click, and then you can inspect, for example, the pixel values to see what the value looks like, all the vector data, raster data, something like that. So it's very easy and intuitive, just similar to the desktop GIS software. And you can also do plotting. For example, sometimes you might want to see, for the remote sensing, you want to see the spectral value to see what the feature looks like, right? For vegetation, for water, for buildings, anything like that. You can also do hyperspectral data. So if you have interest in using hyperspectral data, you can also do some simple plot. It doesn't look nice, but you can customize. You can use all kinds of plotting, begging you like something like this. You can visualize the data. So you can change the color map, you load the imagery. You want to use some different color palette. You can also just do that interactively. All you need to do is click the button, select, and then you can change everything, just like what you used to do in desktop GIS. You can create some method to do, for example, simple comparison, where you can do global scale land cover mapping. All the data is available. You can do compute, and then just visualize them side by side. Basically, you have the original data. You have your classification. You have your prediction, whatever. And you can do some simple visualization. It can also integrate this with desktop GIS, for example, ArcGIS, QGIS. So traditional desktop right now, you can basically access the data catalog because they support Python. And you can run the notebook interactively within the desktop GIS. And so in that way, you have the power of using, so basically you're streaming the data. You are not actually downloading data. Just like you're seeing the Google Basement, right? You can pull the Google Basement on your cell phone. You don't actually download the data to your computer. You can also create some high-quality maps for publication from the Google Journal publication or report, something like that. So you support all kinds of different projections. And essentially, it's downloading the data layer and then create a map, and then it depends on the projection you want. Basically, it supports this kind of plotting capability. So it's not just for within the interface. Sometimes you want some high-quality figures. You can do that as well. And lastly, you can also, once you create something like this, you want to make it accessible to other people. You can also utilize gmap to create a web app. So the web app allows you to basically be on top of gmap and iPad widget and others. So you can just simply transform your Jupyter Notebook into a web application within a couple of clicks. So I have a lot of examples on my GitHub. You just clone the repo and then deploy, for example, a HuggingFace or any other platform you like, and then your app will be up and running. So in that way, if you're an academia, right, traditionally, you have to post your data somewhere on your server or in the cloud, and people need to download. But if the data is pretty huge, like gigabyte-by-gigabyte data, people don't want to download. People want to see what it looks like before you actually spend a lot of time and bandwidth to download data. And this makes it possible. So you can host the data and your app in the cloud. You can expand the URL. You can embed the URL in your manuscript. People try it out and see. So I think this is the future of the geospatial and also internal publication, makes things more reproducible, more accessible. Personally, if I publish the paper, I publish something, I want the people to see it. I mean, in a web app, in some interactive way, not just like, it's good to host the data somewhere, but it's not good enough. Not everyone has the ability to download all the data, has the desktop GIS to load the data and to visualize that. And this just makes it so much easier and it's reproducible because what you do, people run it, you can get the same result. So in that way, you don't have to manipulate because a lot of publications, people manipulate, you can never reproduce what's put in the journal manuscript. So this is, I think, something that is very powerful and very useful. And lastly, I want to show you, there are a lot more additional resources on GitHub, but I presented a tutorial on Tuesday. It's basically about GMAT and Google Search Engine. It's four hours long and I have a Jupyter notebook here in the link. You can check it out. If you want, you can go through and you can reproduce how we present it. And lastly, because I record the video, so you can also check out the video, the full hour YouTube tutorial on YouTube and you can follow through. If you have any questions, you are welcome to reach out or post questions on GitHub. And if you have any questions, you can scan the QR code to connect with me on LinkedIn or just type the URL and I'm happy to talk with you, answer any questions that you may have. Thank you very much for your attention. Thank you. Yes, same thing. So pretty much you can, the same, basically the computation API is the same. The way you access data, the way you do analysis using the same API, the only difference is the visualization because the Python API doesn't have the visualization functionality. And this is where GMAT actually is good for. It helps you visualize, analyze, and also can export the data.
So certainly, yeah, everything will be state of the art. If you are in JavaScript, you create a lot of plots. Using anything related to UI or something, that's not available through Python. But they're also trying to improve. And so actually, I'm working with the Google Sending Team to reorganize the code. And they are going to adopt Gmail as the official package on the documentation in the next probably two to three months. Once we finish that, we'll release. And so in the future, on the documentation, you will see the JavaScript. You're going to see the Gmail code examples are on there. Thank you. So much for that presentation. Thank you. Thank you. Thank you so much. Thank you. You mentioned. So it could be a problem. You are hosting different packages. Every year, there will be a problem. And then each one of them divides the data. Actually, the compute is pretty expensive. So I'm wondering, is this an efficient? Because JavaScript is part of the compute. And it's very powerful. But with Python, back-end, every new instance, data is Google data. A good question. The answer is no. Everything is in the Google Cloud. So you can either access data on the Google Cloud data catalog, or you can have download data to your account. You actually access data directly from the cloud. It doesn't need any. Similar to your Google Drive. Somebody can share a Google Drive, and they can access the data directly, download if you want to. But in all the script, all you need is just basically pointing to the data. And it can run all the analysis using a Google Cloud Compute. So there's nothing happening locally. Everything is on the server. So basically, you can think about the website here, the web app. And the user is here. The Google server is here. So when you're actually accessing the web app, it actually goes to the server, to the compute, and it will return the result, visualize that. So there's basically no limitation. The limitation is what Google allows you to do that. You can upload data. In terms of the Python, the instance and stuff, so the web app that I showed you at the end, that one actually is hosting, for example, Hacking Base. It's all free. And I'm using the framework called Solara. So it actually allows you to turn Jupyter Notebook or Python script directly into a web app, just one line of code. And then the web app will up and running here. So far, it's not really, I mean, in terms of instance, I have no, it's scalable because you can have 10,000 people accessing the same one. And of course, you need to have the front-end server. So that one, it can be on any cloud front-end, for example, Hacking Base or any Google Cloud or Amazon AWS, it's not. So essentially, you just need a server to run the package, to run the Solara package. And I've seen, I'm not sure if I showed it. Yeah, so that in here, you can check out the repo and the web app. So you clone and deploy. Within a minute, you have the web app up and running, and anyone can access that. No, so that's Google. So what is Google? I was saying it's free for research and computation. So all the computation is happening in the Google Cloud, and it's free for research, education, and non-profit. They're also the commercial version. So if you're using for profit, then you will need to pay the license. But it has been free since 2010. So it's still there. Thank you. Yeah, so we have a question. Is there a cost involved with creating web app in Jupyter Notebook? I would like to create one for water quality one. No, it's free. Of course, if you want some of the high computing power or good front-end, then you can pay. But again, the web app there, the repo there, it's easy to produce. You can also check my YouTube channel. I have a video tutorial. I show you step-by-step how you create one and deploy all for free. So personally, I don't want to pay any licensing stuff. All my stuff is free, open source, open access, reproducible, and easy to use. Great, thank you. And we have one more sort of question, slash, if we see the QR code. Okay. Any other questions in the room? Okay. Thank you for your talk. Really quick, I was wondering. Yeah, good question. It's all possible, depending on the image you have. So in the public domain, in the US right now, the best, not satellite, the aerial imagery we have is the USDA net imagery. That one's one meter resolution. So we have national coverage every two, three years. That one certainly can detect some traffic, but it's like two to three years. It's not going to capture the full traffic. But if you have some other data or you have drone imagery, you have something that capture repeatedly, you can upload the data into the cloud, you can do processing. So it all depends on what you have, what you want to use. And if the data can capture it, then you can use the algorithm to detect and analyze and visualize that. But if you're using Landsat, that's not possible because it's 30 meter, less than one pixel. So you need to have at least maybe five to seven pixels wide in order to be probabilistic. Basically, if human can identify the pattern, probably you can find algorithm to do that. But if the imagery, if it actually cannot do that, then no algorithm can actually do the magic. So it all depends on the data you have. Thank you. Other questions in the room? Thank you. Okay. Of course, yeah. So basically, yeah, everything I'm presenting here, I welcome contributors. And so previously, all those projects, I think this is one of those. I have more than like 10, I don't know how many projects, but you can check out my GitHub. You can search open geospatial solutions, or you can check out some of the end of QR code at the end I showed you earlier. You can connect to my GitHub account. And then, so probably it's under my personal account. And actually a local company reached out to me. They want to use that for other commercial applications. They are very prompt to use. It's open source. I don't need, I'm actually licensed all the projects. And, but they are a little bit concerned because I'm the only one doing majority of the work. And if someday that I'm disappear, no longer exist, then it's people, it's not sustainable. So a couple of months ago, I actually created a GitHub organization, open geospatial solutions. So I moved all my majority of those popular packages into the organization. And there are a couple of people in there that in case there's a backup that I'm not there, people can take over and then you can continue to develop and maintain. And contribution is always welcome. Tiny, small feature, even bug report, feature request, all welcome on GitHub. So I try my best to answer questions within 24 hours. I will implement. So I enjoy doing it. I enjoy helping people. I also enjoy creating tools that help my own research. And I also enjoy create, teach people how to create it. Not just that I create and use, but I teach people how to reproduce, how to start from beginning. Also in my GitHub, I have courses that teach from very beginning, how to create a Python package, how to maintain, how to deploy on PyPI and Conda or something like that. Yeah. So again, welcome your contribution. If you have more specific questions, talk to me. I'll be happy to check. Yeah. Thank you. Thanks. We do have one more question. Okay. So what kind of data does, can that adjust at CDF or? GeoTIFF. So PodMaster is GeoTIFF for vector data is straight by, but they are expanding the data format. So hopefully in the future, maybe some support for next lead or pretend maybe any GDAL supported data format. They have no control. It's on the Earth Engine Engineering team, but they are welcome to feedback. So if there's a high volume request or people ask all the time, they will ingest and improve. And they're also building a stack catalog. So in the future, you'll be able to access the data outside the Google Engine Cloud. It's coming in the next couple of months. Thank you very much. Great. Thank you so much.
郭文貴先生 新華社已經發布了消息,您可以查閱。 郭文貴先生 外交部網站為什麼刪除了所有和青岡有關的資訊? 郭文貴先生 外交部網站的資訊按照相關管理規定進行更新。 郭文貴先生 《紐約時報》提問,青岡現在的職責和角色是什麼? 郭文貴先生 14屆全國人大常委會第四次會議的有關決定和中華人民共和國主席令表述的信託,您可以查閱。 郭文貴先生 法新社提問,王毅重新任命為外長,這是一個在找到新的候選人前的過渡性安排,還是長期的安排? 郭文貴先生 這個問題我沒有提供過訊息。 郭文貴先生 我沒有提供過訊息,我還是建議查閱新華社發布的訊息。 路透社提問,謝謝您提出了幾次建議您查閱新華社的相關報導。我們已經看過這個報導,報導裡面並沒有說青岡為什麼現在不是外長。我想重新問一下,為什麼她現在不是外長? 郭文貴先生 大家都非常關心外交部長的任免,我注意到今天已經有好幾位同事提了不少相關相似甚至相同的問題,今天來的記者朋友也非常多,我願意再一併地對這個問題做個答覆。 關於中國外交部長的任免,新華社已經發布了消息,十四屆全國人大常委會第四次會議做出的有關決定和中華人民共和國主席令表述得很清楚,建議大家查閱,我沒有更多的訊息。 郭文貴先生 下一個問題。 我已經回答了有關問題,首先關於外交部長的任免,請以新華社發布的消息為準,請你查閱有關的信息,外交部網站的信息我們根據有關的管理規定進行更新。 您應該看到中國外交活動都在穩步向前推進。 我沒有可以提供的信息。 下一個問題。 還是關於青岡,就是青岡目前人在那裡,就是你有這方面的消息嗎?謝謝。 我沒有可以提供的信息。 下一個問題。 謝謝,日本交流電視台,還是青岡外長的問題,青岡外長當然外長是只有半年,這麼短的時間內更換外長,對中國外交有什麼樣的影響? 剛剛我已經說了,中國的外交活動都在穩步向前推進。 我不瞭解你說的情況,我已經介紹了關於青岡的事情,我已經介紹了關於青岡的事情,我已經介紹了關於青岡的事情,我已經介紹了關於青岡的事情。 下一個問題。 謝謝,路透社。 我們注意到外交部發言人6月底左右有一次發布會說,青岡因為身體原因而不去ASEAN峰會,那麼我們是不是應該理解他現在不當候選人了? 我們注意到外交部發言人6月底左右有一次發布會說,青岡因為身體原因而不去ASEAN峰會,那麼我們是不是應該理解他現在不當候選人了? 我沒有可以提供的信息。 下一個問題。 謝謝,路透社。 再問一下剛才你說新華社的相關報導已經表達得非常清楚現在的情況,你說你認為非常清楚,那麼對我們來說還是不太清楚,所以想再問一下他不是外長這個事情,為什麼你覺得清楚?他清楚在哪裡?謝謝。 我已經回答過這個問題,新華社已經發布了消息,除此之外我沒有更多的信息。 下一個問題。 那你作為發言人,你如何評價青岡就擔任外交部部長這個7個月的工作? 我可能不是回答這個問題的合適人選,我覺得我不適合做出評價。 下一個問題。 謝謝,路透社。 想問一下中國政府希望外界通過青岡最近這個事情了解什麼,學到什麼? 這個取決於大家,這是中國政府可以決定的嗎?我們只是正常的發布了信息。 我能問問你嗎?你了解到什麼,學到什麼? 下一個問題。 謝謝,我是日本交流電視臺。我看了國務院的網站上,青岡外長還是擔任國務委員,還是擔任外交的國務委員嗎? 剛剛我已經回答了相關的問題,沒有更多的信息。 下一個問題。 對於中美關係,中方一貫按照相互尊重和平共處合作共贏三原則來看待和發展,我們也就各個層級的對話和交流保持著溝通。 下一個問題。 總的原則來說,中國的國務委員和外交部的這個職責劃分是怎麼樣的? 這個問題應該超出了我能回答的範圍。 下一個問題。 剛剛我已經回答了相關的問題,中國外交活動都在穩步向前推進。 還有其他問題嗎? 那好,今天的記者會到此結束,謝謝大家。 煩死了!
